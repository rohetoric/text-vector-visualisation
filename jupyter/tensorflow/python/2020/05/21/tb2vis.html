<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Visualising Word Vectors Using TF2 [Advisable] | Text Vector Visualisation</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Visualising Word Vectors Using TF2 [Advisable]" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Exploration and Visualisation of Word Vectors Using TensorFlow 2" />
<meta property="og:description" content="Exploration and Visualisation of Word Vectors Using TensorFlow 2" />
<link rel="canonical" href="https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html" />
<meta property="og:url" content="https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html" />
<meta property="og:site_name" content="Text Vector Visualisation" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-21T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Exploration and Visualisation of Word Vectors Using TensorFlow 2","@type":"BlogPosting","headline":"Visualising Word Vectors Using TF2 [Advisable]","dateModified":"2020-05-21T00:00:00-05:00","datePublished":"2020-05-21T00:00:00-05:00","url":"https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/text-vector-visualisation/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://rohetoric.github.io/text-vector-visualisation/feed.xml" title="Text Vector Visualisation" /><link rel="shortcut icon" type="image/x-icon" href="/text-vector-visualisation/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Visualising Word Vectors Using TF2 [Advisable] | Text Vector Visualisation</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Visualising Word Vectors Using TF2 [Advisable]" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Exploration and Visualisation of Word Vectors Using TensorFlow 2" />
<meta property="og:description" content="Exploration and Visualisation of Word Vectors Using TensorFlow 2" />
<link rel="canonical" href="https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html" />
<meta property="og:url" content="https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html" />
<meta property="og:site_name" content="Text Vector Visualisation" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-21T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Exploration and Visualisation of Word Vectors Using TensorFlow 2","@type":"BlogPosting","headline":"Visualising Word Vectors Using TF2 [Advisable]","dateModified":"2020-05-21T00:00:00-05:00","datePublished":"2020-05-21T00:00:00-05:00","url":"https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://rohetoric.github.io/text-vector-visualisation/feed.xml" title="Text Vector Visualisation" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/text-vector-visualisation/">Text Vector Visualisation</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/text-vector-visualisation/about/">About Me</a><a class="page-link" href="/text-vector-visualisation/search/">Search</a><a class="page-link" href="/text-vector-visualisation/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Visualising Word Vectors Using TF2 [Advisable]</h1><p class="page-description">Exploration and Visualisation of Word Vectors Using TensorFlow 2</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-05-21T00:00:00-05:00" itemprop="datePublished">
        May 21, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/text-vector-visualisation/categories/#jupyter">jupyter</a>
        &nbsp;
      
        <a class="category-tags-link" href="/text-vector-visualisation/categories/#tensorflow">tensorflow</a>
        &nbsp;
      
        <a class="category-tags-link" href="/text-vector-visualisation/categories/#python">python</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/rohetoric/text-vector-visualisation/tree/master/_notebooks/2020-05-21-tb2vis.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/text-vector-visualisation/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/rohetoric/text-vector-visualisation/blob/master/_notebooks/2020-05-21-tb2vis.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/text-vector-visualisation/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-21-tb2vis.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Tensorflow released their latest version of <a href="https://www.youtube.com/watch?v=k5c-vg4rjBw">TensorFlow 2</a> on September 30, 2019.</p>
<p>As also mentioned in <font color="red">tb1vis.ipynb</font> the reason we are visualising FastText is because:</p>
<blockquote>
FastText uses the concept that embeddings are formed based on the sub-word approach, this method helps us to visualise and obtain misspellings of a word or different spellings of the same word.</blockquote><p>I couldn't find any blogs on the Internet that have covered or updated their code which describes the visualisation of embeddings through the latest version of Tensorflow.</p>
<p>Although I did take the help of an issue <a href="https://github.com/tensorflow/tensorboard/issues/2471 ">TF 2.0 API for using the embedding projector</a> raised on the Tensorflow repository and have come to a concluding notebook suiting my goal i.e. to visualise FastText embeddings using TF2.</p>
<p>The tensorflow version used in this notebook is version 2.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog-post/images/copied_from_nb/my_icons/tf2.png" alt="&quot;TensorFlow 2&quot;" /></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># import statements</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">PurePath</span>

<span class="kn">import</span> <span class="nn">fasttext</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">ops</span>

<span class="kn">from</span> <span class="nn">tensorboard.plugins</span> <span class="kn">import</span> <span class="n">projector</span>
<span class="kn">from</span> <span class="nn">tensorboard.plugins.projector</span> <span class="kn">import</span> <span class="n">ProjectorConfig</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#hide_output</span>

<span class="c1"># load pre-trained fasttext model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">fasttext</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;fasttextmodel.bin&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_words</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>s
said
mr
&lt;/s&gt;
people
new
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#hide_output</span>

<span class="c1"># number of words in the dataset</span>
<span class="n">VOCAB_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_words</span><span class="p">())</span>


<span class="c1"># size of the dimension of each word vector</span>
<span class="n">EMBEDDING_DIM</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_word_vector</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>


<span class="c1"># 2D numpy array initialised to store words with their vector representation</span>
<span class="n">embed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">VOCAB_SIZE</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">))</span>
<span class="n">embed</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># store the vector representation of each word in the 2D numpy array</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_words</span><span class="p">()):</span>
    <span class="n">embed</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_word_vector</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="n">embed</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[-0.11363645,  0.00304414,  0.00589875, ...,  0.00278742,
         0.03564256, -0.10496949],
       [ 0.05821591,  0.07343163, -0.06941246, ...,  0.00737938,
         0.08668958, -0.05127012],
       [ 0.06867523, -0.02112868, -0.02132288, ...,  0.05362611,
         0.13982825,  0.04221647],
       ...,
       [ 0.16511762,  0.04439345, -0.14276202, ...,  0.02632121,
         0.03970968,  0.03706815],
       [ 0.09471416,  0.09356211,  0.00358974, ..., -0.0174412 ,
         0.13414964,  0.02268019],
       [ 0.07753251, -0.02356024, -0.05303693, ...,  0.14130574,
         0.09740689,  0.0418443 ]])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># path to store the words</span>
<span class="n">tsv_file_path</span> <span class="o">=</span> <span class="s2">&quot;tensorboard/metadata.tsv&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Projection-on-Tensorboard-2">Projection on Tensorboard 2<a class="anchor-link" href="#Projection-on-Tensorboard-2"> </a></h3><p>Steps for projection:</p>
<ol>
<li>Define the function <code>register_embedding()</code> and <code>save_label_tsv()</code> to configure the projector as well as save the projector configuration files and metadata file to the same folder.</li>
<li>Initialise the path variables accordingly and call the above function with suitable path variables as shown in below cells.</li>
<li>Creation of the tensorflow variable instead of tensorflow placeholder.</li>
<li>A saver class object is initialised and checkpoint is created. </li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Differences-between-TF-1-and-TF-2">Differences between TF 1 and TF 2<a class="anchor-link" href="#Differences-between-TF-1-and-TF-2"> </a></h3><ol>
<li>We cannot call the reset default graph method directly from tf library which we did for TensorFlow 1. It is invoked in TF2 as: </li>
</ol>
<p><code>from tensorflow.python.framework import ops
ops.reset_default_graph()</code></p>
<ol>
<li>There is no placeholder required here. A tf variable is created which is passed parameters. A TF variable is  shown below. Here the parameters are x: the array which contains the embeddings and name: name of the embedding file.</li>
</ol>
<p><code>tensor_embeddings = tf.Variable(x, name=EMBEDDINGS_TENSOR_NAME)</code>
According to the TF2 documentation a <a href="https://www.tensorflow.org/guide/variable">tensorflow variable</a> is defined as:</p>
<blockquote>
A variable maintains shared, persistent state manipulated by a program.

  The *Variable()* constructor requires an initial value for the variable, which
  can be a *Tensor* of any type and shape. This initial value defines the type
  and shape of the variable. After construction, the type and shape of the
  variable are fixed. The value can be changed using one of the assign methods.
</blockquote><ol>
<li>There is no concept of <code>session</code> as well as <code>saver</code> in TF2 yet. To workaround this, we just use the <code>saver</code> class for the creation of checkpoints by initialising the <code>saver</code> object with the tensorflow variable and pass <code>None</code> as value to the <code>session</code> parameter in <code>saver.save()</code>.</li>
</ol>
<p><code>saver = tf.compat.v1.train.Saver([tensor_embeddings])  
saver.save(sess=None, global_step=STEP, save_path=EMBEDDINGS_FPATH)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ops</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>  <span class="c1"># clearing the default graph stack</span>


<span class="k">def</span> <span class="nf">register_embedding</span><span class="p">(</span>
    <span class="n">embedding_tensor_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">meta_data_fname</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configuring the projector to be read by the tensorboard.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">    embedding_tensor_name(str): embeddings file name</span>
<span class="sd">    meta_data_fname(str): metadata file name</span>
<span class="sd">    log_dir(str): folder where tensorboard files and the metadata file are saved</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    None    </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">projector</span><span class="o">.</span><span class="n">ProjectorConfig</span><span class="p">()</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
    <span class="n">embedding</span><span class="o">.</span><span class="n">tensor_name</span> <span class="o">=</span> <span class="n">embedding_tensor_name</span>
    <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="n">meta_data_fname</span>
    <span class="n">projector</span><span class="o">.</span><span class="n">visualize_embeddings</span><span class="p">(</span>
        <span class="n">log_dir</span><span class="p">,</span> <span class="n">config</span>
    <span class="p">)</span>  <span class="c1"># storing the configuration files of projector where tensorboard files are saved</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">save_labels_tsv</span><span class="p">(</span><span class="n">labels</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">filepath</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Storing the vocabulary of words in the dataset to a file</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">    labels: vocabulary i.e. words in the dataset</span>
<span class="sd">    filepath: metadata file name</span>
<span class="sd">    log_dir: &quot;folder where tensorboard files and projector files are saved</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    None  </span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">PurePath</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">filepath</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LOG_DIR</span> <span class="o">=</span> <span class="s2">&quot;tb2files&quot;</span>  <span class="c1"># folder which will contain all the tensorboard log files</span>

<span class="c1"># Labels i.e. the words in the dataset will be stored in this file</span>
<span class="n">META_DATA_FNAME</span> <span class="o">=</span> <span class="s2">&quot;meta.tsv&quot;</span>

<span class="c1"># name of the file which will have the embeddings stored</span>
<span class="n">EMBEDDINGS_TENSOR_NAME</span> <span class="o">=</span> <span class="s2">&quot;embeddings&quot;</span>

<span class="c1"># path for checkpoint of the saved embeddings</span>
<span class="n">EMBEDDINGS_FPATH</span> <span class="o">=</span> <span class="n">PurePath</span><span class="p">(</span><span class="n">LOG_DIR</span><span class="p">,</span> <span class="n">EMBEDDINGS_TENSOR_NAME</span> <span class="o">+</span> <span class="s2">&quot;.ckpt&quot;</span><span class="p">)</span>
<span class="n">STEP</span> <span class="o">=</span> <span class="mi">0</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">embed</span>  <span class="c1"># array containing the embeddings</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_words</span><span class="p">()</span>  <span class="c1"># list containing the vocabulary</span>
<span class="n">register_embedding</span><span class="p">(</span><span class="n">EMBEDDINGS_TENSOR_NAME</span><span class="p">,</span> <span class="n">META_DATA_FNAME</span><span class="p">,</span> <span class="n">LOG_DIR</span><span class="p">)</span>
<span class="n">save_labels_tsv</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">META_DATA_FNAME</span><span class="p">,</span> <span class="n">LOG_DIR</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tensor_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">EMBEDDINGS_TENSOR_NAME</span>
<span class="p">)</span>  <span class="c1"># creation of the tensorflow variable, x: array which contains the embeddings,</span>
<span class="c1"># name: name of the file which will have the embeddings stored</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#hide_output</span>

<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span>
    <span class="p">[</span><span class="n">tensor_embeddings</span><span class="p">]</span>
<span class="p">)</span>  <span class="c1"># Tensorflow variable passed as argument for saver object to be initialised</span>
<span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
    <span class="n">sess</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">STEP</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="n">EMBEDDINGS_FPATH</span>
<span class="p">)</span>  <span class="c1"># saving the checkpoint for the embedding files</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr />

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="rohetoric/text-vector-visualisation"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/text-vector-visualisation/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/text-vector-visualisation/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/text-vector-visualisation/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Visualisation of FastText Vectors Using TensorFlow 1 and 2</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/rohetoric" title="rohetoric"><svg class="svg-icon grey"><use xlink:href="/text-vector-visualisation/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/rohit-bhardwaj-a81737128" title="rohit-bhardwaj-a81737128"><svg class="svg-icon grey"><use xlink:href="/text-vector-visualisation/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/rohetoric" title="rohetoric"><svg class="svg-icon grey"><use xlink:href="/text-vector-visualisation/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
